# FluxCore Runtime â€” AnÃ¡lisis ArquitectÃ³nico Completo

**Fecha:** 2026-02-09 (actualizado tras Fase 1 Limpieza)  
**Alcance:** Todo el runtime de IA: orquestaciÃ³n, extensiÃ³n, ejecuciÃ³n, RAG, tools, crÃ©ditos  
**Veredicto general:** Funcional, deuda tÃ©cnica reducida tras Fase 1. No es enterprise-ready aÃºn. No soporta multi-agente.

---

## 1. ARQUITECTURA ACTUAL â€” FLUJO COMPLETO DE UN MENSAJE

```
Usuario envÃ­a mensaje
       â”‚
       â–¼
  MessageCore.receive()          â† core/message-core.ts
       â”‚
       â”œâ”€ 1. Persistir mensaje (DB)
       â”œâ”€ 2. WebSocket broadcast
       â”œâ”€ 3. AutomationController.evaluateTrigger()
       â”œâ”€ 4. ExtensionHost.processMessage()  â† NO genera IA aquÃ­
       â””â”€ 5. CoreEventBus.emit('core:message_received')
                    â”‚
                    â–¼
           AIOrchestrator         â† ai-orchestrator.service.ts
                    â”‚
                    â”œâ”€ Validaciones (success, automatic mode, text)
                    â”œâ”€ Debounce por conversaciÃ³n (setTimeout)
                    â””â”€ extensionHost.generateAIResponse()
                              â”‚
                              â–¼
                    AIService.generateResponse()   â† ai.service.ts
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â–¼         â”‚
          resolveExecutionPlan()     â† ai-execution-plan.service.ts
                    â”‚
                    â”œâ”€ resolveActiveAssistant()
                    â”œâ”€ Check extension_installations
                    â”œâ”€ Extract modelConfig/timingConfig
                    â”œâ”€ Check entitlements
                    â”œâ”€ Check API keys
                    â”œâ”€ Credits gating (OpenAI)
                    â””â”€ Build providerOrder
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â–¼         â”‚
             runtime === 'openai'?
                /           \
               SI            NO
               â”‚              â”‚
     executeOpenAIAssistantsPath()    extension.generateSuggestion()
               â”‚                              â”‚
               â–¼                              â–¼
     runAssistantWithMessages()      FluxCoreExtension (local)
     (openai-sync.service.ts)        (extensions/fluxcore/src/index.ts)
               â”‚                              |
               |                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
               |                    â–¼         |
               |          fetchActiveAssistant() â† RuntimeServices (inyecciÃ³n directa)
               |          buildPrompt()
               |          getToolsForAssistant()
               |          createChatCompletionWithFallback(config)
               â”‚                    â”‚
               â”‚                    â”œâ”€ Tool loop (max 2 rounds)
               â”‚                    â”‚   â”œâ”€ search_knowledge
               â”‚                    â”‚   â”œâ”€ list_available_templates
               â”‚                    â”‚   â””â”€ send_template
               â”‚                    â”‚
               â”‚                    â””â”€ Build AISuggestion
               â”‚                              â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                              â–¼
                                   AIOrchestrator
                                   messageCore.send() â† respuesta final
```

---

## 2. LO QUE ESTÃ BIEN (Aciertos)

### 2.1 ExecutionPlan como Single Source of Truth
El patrÃ³n `resolveExecutionPlan()` es sÃ³lido. Resuelve assistant, provider, crÃ©ditos y elegibilidad en **un solo paso** antes de tocar la extensiÃ³n. Discriminated union (`EligiblePlan | BlockedPlan`) es tipado correcto.

### 2.2 CoreEventBus + AIOrchestrator desacoplados
El core de mensajerÃ­a NO conoce la IA. Emite un evento (`core:message_received`) y el orchestrator escucha. Esto respeta TOTEM (IA es extensiÃ³n, no nÃºcleo).

### 2.3 RAG-as-Tool
El modelo decide si buscar en la base de conocimiento vÃ­a function calling (`search_knowledge`). Elimina bÃºsquedas innecesarias para mensajes como "ok", "gracias". Buena decisiÃ³n arquitectÃ³nica.

### 2.4 ToolRegistry extensible
El `ToolRegistry` en la extensiÃ³n es un patrÃ³n limpio: recibe dependencias por inyecciÃ³n, decide quÃ© tools ofrecer segÃºn el contexto del asistente.

### 2.5 Provider fallback con retry
`createChatCompletionWithFallback()` implementa retry con exponential backoff, mapeo de modelos entre providers, y fallback automÃ¡tico de tools si causan `bad_request`.

### 2.6 Trace/Debug completo
Cada ejecuciÃ³n genera un `AITraceEntry` con attempts, tool usage, request bodies, timing. Ãštil para debugging en producciÃ³n.

---

## 3. FALLAS CRÃTICAS

### 3.1 âœ… ~~CÃ³digo muerto: `processMessage()` duplica `generateResponse()`~~ **RESUELTO**

> Eliminado en Fase 1. Se borraron `processMessage()` (~310 lÃ­neas), `applyCreditsGating()` (~65 lÃ­neas) e imports no usados. `getAccountConfig()` se mantuvo temporalmente (tiene callers vivos: `getAutoReplyDelayMs`, `getStatusForAccount`).

### 3.2 âœ… ~~La extensiÃ³n se llama a sÃ­ misma via HTTP~~ **RESUELTO**

> Eliminado en Fase 1. Se implementÃ³ `RuntimeServices` injection: `ai.service.ts` inyecta `resolveActiveAssistant`, `fetchRagContext`, `listTemplates`, `sendTemplate` directamente en la extensiÃ³n via `setRuntimeServices()`. Los 4 mÃ©todos HTTP (`fetchActiveAssistant`, `listAuthorizedTemplates`, `sendTemplateTool`, `fetchRAGContext`) ahora usan los servicios inyectados con fallback HTTP para backward compatibility.

### 3.3 ï¿½ Doble resoluciÃ³n del assistant (parcialmente resuelto)
Cuando el orchestrator llama a `generateResponse()`:
1. `resolveExecutionPlan()` llama a `resolveActiveAssistant()` â†’ DB query completa
2. Luego `extension.generateSuggestion()` llama `fetchActiveAssistant()` â†’ ahora via servicio inyectado (sin HTTP), pero sigue siendo una segunda query

> **Mejora en Fase 1:** Ya no hay HTTP round-trip, pero la doble query a DB persiste. OptimizaciÃ³n futura: pasar la composition ya resuelta como parÃ¡metro.

### 3.4 âœ… ~~`ai.service.ts` es un God Object (1596 lÃ­neas)~~ **RESUELTO**

> Descompuesto en Fase 1 usando Extract & Delegate:
> - `ai-branding.service.ts` â€” funciones puras de branding/promo
> - `ai-suggestion-store.ts` â€” CRUD de suggestions en memoria
> - `ai-trace.service.ts` â€” delegaciÃ³n de traces a la extensiÃ³n
> - `ai-context.service.ts` â€” buildContext() (queries DB)
> - `ai.service.ts` ahora es un orquestador delgado (~1070 lÃ­neas) que delega a los servicios extraÃ­dos. La API pÃºblica no cambiÃ³.

### 3.5 âœ… ~~Config mutation en lugar de inmutabilidad~~ **RESUELTO**

> Corregido en Fase 1. `generateSuggestion()` ahora acepta `configOverride?: FluxCoreConfig` como 4to parÃ¡metro. `ai.service.ts` pasa `requestConfig` desde el ExecutionPlan directamente â€” ya no llama `onConfigChange()`. `getProviderOrder()` y `createChatCompletionWithFallback()` tambiÃ©n reciben config por parÃ¡metro. El singleton ya no muta estado entre requests concurrentes.

### 3.6 ğŸ”´ Logging excesivo en producciÃ³n
Hay ~80+ `console.log()` en `ai.service.ts` y ~40+ en `extensions/fluxcore/src/index.ts`. En producciÃ³n esto genera ruido masivo. No hay niveles de log (debug vs info vs warn).

### 3.7 ğŸŸ¡ Tipos `any` por doquier
```typescript
type ContextData = any;  // ai.service.ts:50
```
El tipo de contexto es `any` en el servicio principal. Los cast `as any` se usan extensivamente para bypasear TypeScript.

---

## 4. PUNTOS CRÃTICOS (Riesgos)

### 4.1 Single-threaded bottleneck
Todo corre en un solo proceso Bun. Si una llamada a OpenAI tarda 15 segundos, bloquea el event loop para todos los demÃ¡s usuarios. No hay worker threads ni queue system.

### 4.2 Suggestions en memoria (no persisten)
```typescript
const suggestions: Map<string, AISuggestion> = new Map();
```
Si el server se reinicia, se pierden todas las suggestions pendientes y traces.

### 4.3 Sin rate limiting por cuenta
No hay protecciÃ³n contra un usuario que envÃ­e 100 mensajes en 1 segundo. El debounce del orchestrator solo agrupa mensajes de la misma conversaciÃ³n, pero no limita el throughput global.

### 4.4 Sin circuit breaker
Si OpenAI estÃ¡ caÃ­do, el sistema va a reintentar indefinidamente (hasta el timeout de 15s) por cada mensaje. No hay circuit breaker que detenga los intentos despuÃ©s de N fallos consecutivos.

---

## 5. Â¿ES ENTERPRISE-READY?

**No.** Faltan estos pilares enterprise:

| Pilar | Estado actual | Necesario |
|-------|--------------|-----------|
| **Multi-tenancy isolation** | Config mutada en singleton compartido | Config per-request, inmutable |
| **Horizontal scaling** | Single process, state en memoria | Stateless workers + Redis/queue |
| **Observability** | console.log | Structured logging, OpenTelemetry, metrics |
| **Fault tolerance** | Sin circuit breaker, sin retry queue | Circuit breakers, dead letter queues |
| **Security** | API keys en env vars compartidas | Per-tenant key vault, key rotation |
| **Rate limiting** | Ninguno | Per-account, per-provider throttling |
| **Audit trail** | Traces en memoria | Traces persistidos, compliance-ready |
| **A/B testing** | Ninguno | Feature flags, canary deployments |
| **Multi-agent** | âŒ No existe | Orchestration layer, agent graphs |

---

## 6. Â¿ESTÃ PREPARADO PARA HACER LOS MEJORES AGENTES?

**No.** El sistema actual es un **single-agent monolÃ­tico**. Un asistente recibe un mensaje, genera una respuesta. No hay:

- **No hay composiciÃ³n de agentes**: No se puede crear un pipeline donde Agent A analiza la intenciÃ³n, Agent B busca informaciÃ³n, Agent C formula la respuesta
- **No hay routing inteligente**: No hay un "router agent" que decida quÃ© sub-agente usar
- **No hay estado de conversaciÃ³n multi-step**: No hay memoria de working state entre turnos (solo el historial de mensajes crudos)
- **No hay ejecuciÃ³n determinista**: Todo depende del LLM. No hay steps deterministas intercalados
- **No hay grafos de ejecuciÃ³n**: No se puede definir "si el usuario pide X, ejecutar workflow Y con steps [Aâ†’Bâ†’C]"
- **No hay evaluaciÃ³n de calidad**: No hay self-critique, no hay verificaciÃ³n de output

---

## 7. PROPUESTA: ARQUITECTURA MICRO-AGENTES

### 7.1 Concepto: Agent Graph + Deterministic Steps

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Agent Orchestrator    â”‚
                    â”‚  (Deterministic Router)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼              â–¼              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Intent    â”‚  â”‚ Knowledgeâ”‚  â”‚ Action   â”‚
        â”‚ Classifierâ”‚  â”‚ Agent    â”‚  â”‚ Executor â”‚
        â”‚ (LLM)     â”‚  â”‚ (RAG)    â”‚  â”‚ (Tools)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚              â”‚              â”‚
              â–¼              â–¼              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Response  â”‚  â”‚ Quality  â”‚  â”‚ Guard    â”‚
        â”‚ Generator â”‚  â”‚ Checker  â”‚  â”‚ Rails    â”‚
        â”‚ (LLM)     â”‚  â”‚ (Det.)   â”‚  â”‚ (Det.)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 DefiniciÃ³n de un Agent Flow (JSON)

Un asistente autorizado podrÃ­a crear un flujo desde un JSON como este:

```json
{
  "id": "customer-support-flow",
  "name": "Soporte al Cliente",
  "version": "1.0",
  "trigger": { "type": "message_received" },
  "agents": [
    {
      "id": "intent-classifier",
      "type": "llm",
      "model": "llama-3.1-8b-instant",
      "systemPrompt": "Clasifica la intenciÃ³n del usuario en: pregunta_producto, queja, saludo, otro",
      "outputSchema": {
        "type": "object",
        "properties": {
          "intent": { "enum": ["pregunta_producto", "queja", "saludo", "otro"] },
          "confidence": { "type": "number" },
          "entities": { "type": "object" }
        }
      },
      "maxTokens": 100,
      "temperature": 0.1
    },
    {
      "id": "knowledge-lookup",
      "type": "rag",
      "condition": "{{ intent-classifier.intent == 'pregunta_producto' }}",
      "vectorStoreIds": ["vs_productos"],
      "topK": 5,
      "minScore": 0.3
    },
    {
      "id": "response-generator",
      "type": "llm",
      "model": "gpt-4o-mini",
      "systemPrompt": "Genera una respuesta usando el contexto proporcionado...",
      "inputs": {
        "user_message": "{{ trigger.content }}",
        "intent": "{{ intent-classifier.intent }}",
        "knowledge": "{{ knowledge-lookup.context }}",
        "customer_history": "{{ context.relationship }}"
      },
      "maxTokens": 500,
      "temperature": 0.7
    },
    {
      "id": "quality-gate",
      "type": "deterministic",
      "checks": [
        { "rule": "response.length > 10", "action": "pass" },
        { "rule": "response.contains_pii", "action": "redact" },
        { "rule": "confidence < 0.5", "action": "escalate_to_human" }
      ]
    },
    {
      "id": "send-template",
      "type": "tool",
      "condition": "{{ intent-classifier.intent == 'queja' && quality-gate.action == 'pass' }}",
      "tool": "send_template",
      "params": {
        "templateId": "complaint-acknowledgment",
        "variables": { "name": "{{ context.relationship.contactName }}" }
      }
    }
  ],
  "scopes": {
    "allowedModels": ["llama-3.1-8b-instant", "gpt-4o-mini"],
    "maxTotalTokens": 2000,
    "maxExecutionTimeMs": 30000,
    "allowedTools": ["search_knowledge", "send_template"],
    "canCreateSubAgents": false
  }
}
```

### 7.3 QuÃ© se necesita construir

#### Capa 1: Agent Runtime Engine
```
apps/api/src/services/agent-runtime/
â”œâ”€â”€ engine.ts              â€” Ejecuta un AgentFlow (graph walker)
â”œâ”€â”€ agent-types.ts         â€” LLMAgent, RAGAgent, DeterministicAgent, ToolAgent
â”œâ”€â”€ context-bus.ts         â€” Shared context entre agents (inmutable, append-only)
â”œâ”€â”€ condition-evaluator.ts â€” EvalÃºa expresiones tipo {{ intent == 'x' }}
â”œâ”€â”€ scope-enforcer.ts      â€” Valida lÃ­mites (tokens, tiempo, tools)
â””â”€â”€ flow-registry.ts       â€” CRUD de AgentFlows (DB-backed)
```

#### Capa 2: Agent Types

| Tipo | Comportamiento | Determinista? |
|------|---------------|---------------|
| `llm` | Llama a un LLM con system prompt + inputs | No |
| `rag` | Busca en vector stores | Semi (query es del paso anterior) |
| `deterministic` | Reglas if/then/else | SÃ­ |
| `tool` | Ejecuta una tool registrada | SÃ­ |
| `router` | Decide quÃ© branch del grafo seguir | Configurable |
| `human-in-loop` | Pausa y espera aprobaciÃ³n humana | SÃ­ |
| `transform` | Transforma data (map, filter, extract) | SÃ­ |

#### Capa 3: Scoped Execution
Cada flow se ejecuta dentro de un **scope** que define:
- QuÃ© modelos puede usar
- CuÃ¡ntos tokens puede consumir
- QuÃ© tools puede invocar
- Tiempo mÃ¡ximo de ejecuciÃ³n
- Si puede crear sub-flujos

Esto permite que un asistente autorizado cree flujos sin riesgo de escalada de privilegios.

---

## 8. SIMPLIFICACIÃ“N INMEDIATA DEL CÃ“DIGO ACTUAL

### 8.1 Eliminar dead code
- **Borrar `processMessage()`** de `ai.service.ts` (~300 lÃ­neas)
- **Borrar `applyCreditsGating()`** â€” ya lo hace `resolveExecutionPlan`
- **Borrar `getAccountConfig()` completo** â€” duplica lÃ³gica del ExecutionPlan

### 8.2 Eliminar HTTP self-calls en la extensiÃ³n
En lugar de que la extensiÃ³n haga `fetch(localhost:3000/...)`, pasar la data como parÃ¡metro:

```typescript
// ANTES (malo):
const active = await this.fetchActiveAssistant(recipientAccountId); // HTTP call

// DESPUÃ‰S (bueno):
async generateSuggestion(event, context, recipientAccountId, composition) {
  // composition ya viene resuelta del ExecutionPlan
}
```

Esto elimina ~4 HTTP round-trips por mensaje.

### 8.3 Config inmutable per-request
```typescript
// ANTES (race condition):
await extension.onConfigChange(recipientAccountId, { ... });
const suggestion = await extension.generateSuggestion(event, context, recipientAccountId);

// DESPUÃ‰S (seguro):
const suggestion = await extension.generateSuggestion(event, context, {
  accountId: recipientAccountId,
  config: { model, temperature, providerOrder, ... },  // inmutable per-request
  composition,  // ya resuelto
});
```

### 8.4 Descomponer ai.service.ts
```
ai.service.ts (1596 lÃ­neas) â†’
â”œâ”€â”€ ai-generation.service.ts    â€” generateResponse() + OpenAI path
â”œâ”€â”€ ai-context.service.ts       â€” buildContext()
â”œâ”€â”€ ai-branding.service.ts      â€” promo markers, branding footer
â”œâ”€â”€ ai-suggestion-store.ts      â€” CRUD suggestions (migrar a Redis)
â””â”€â”€ ai-trace.service.ts         â€” listTraces, getTrace, exportTraces
```

### 8.5 Structured logging
Reemplazar `console.log('[ai-service] ...')` con:
```typescript
import { logger } from '../utils/logger';
logger.info('generateResponse', { accountId, runtime, provider, elapsedMs });
logger.debug('providerOrder', { providers: providerOrder.map(p => p.provider) });
```

---

## 9. ROADMAP PROPUESTO â€” CON ANÃLISIS DE RIESGOS

---

### Fase 1: Limpieza (1-2 semanas) âœ… COMPLETADA 2026-02-09

#### 1.1 Eliminar `processMessage()` dead code

**Â¿PodrÃ­a romper algo?** â†’ **NO.** Verificado por grep exhaustivo del codebase:

- `aiService.processMessage()` (lÃ­neas 235-546 de `ai.service.ts`) **no es invocado por ningÃºn archivo**.
- La Ãºnica referencia es un **comentario** en `ai-execution-plan.service.ts` lÃ­nea 11.
- El AIOrchestrator usa `extensionHost.generateAIResponse()` â†’ `aiService.generateResponse()`. Nunca pasa por `processMessage()`.
- **OJO**: `extensionHost.processMessage()` (en `extension-host.service.ts`) es un mÃ©todo **distinto** que SÃ se usa â€” procesa hooks de extensiones. No confundir.

**QuÃ© borrar exactamente:**
- `ai.service.ts` â†’ mÃ©todo `processMessage()` (~310 lÃ­neas)
- `ai.service.ts` â†’ mÃ©todo `applyCreditsGating()` (~65 lÃ­neas) â€” ya lo hace `resolveExecutionPlan`
- `ai.service.ts` â†’ mÃ©todo `getAccountConfig()` (~140 lÃ­neas) â€” duplica lÃ³gica del ExecutionPlan

**Total a eliminar:** ~515 lÃ­neas de dead code. Cero riesgo funcional.

#### 1.2 Eliminar HTTP self-calls en extensiÃ³n

**Â¿PodrÃ­a romper algo?** â†’ **SÃ, si se hace mal.** Requiere cuidado pero es seguro si se sigue el patrÃ³n correcto.

La extensiÃ³n FluxCore hace **4 HTTP round-trips a localhost** por mensaje:

| MÃ©todo | Ruta | Tipo |
|--------|------|------|
| `fetchActiveAssistant()` | `GET /fluxcore/runtime/active-assistant` | Lectura de datos |
| `listAuthorizedTemplates()` | `POST /fluxcore/runtime/tools/list-templates` | Lectura de datos |
| `sendTemplateTool()` | `POST /fluxcore/runtime/tools/send-template` | **Efecto secundario** (envÃ­a mensaje) |
| `fetchRAGContext()` | `POST /fluxcore/runtime/rag-context` | Lectura de datos |

**Sobre la cuenta de FluxCore:** La cuenta `@fluxcore` que chatea con usuarios opera a travÃ©s del flujo normal de `MessageCore.receive()` â†’ `coreEventBus.emit()` â†’ `AIOrchestrator`. Los HTTP self-calls son internos a la extensiÃ³n para obtener data del API server que la hospeda. Eliminar los self-calls **NO afecta** la cuenta `@fluxcore` ni su capacidad de chatear.

**CÃ³mo migrar sin romper:**

```typescript
// 1. fetchActiveAssistant() â†’ Ya viene en el ExecutionPlan
//    resolveExecutionPlan() ya llama resolveActiveAssistant() y devuelve composition
//    Solo hay que pasar composition como parÃ¡metro a generateSuggestion()

// 2. fetchRAGContext() â†’ Inyectar el servicio directo
//    En vez de HTTP, importar el servicio de RAG y llamarlo in-process

// 3. listAuthorizedTemplates() â†’ Inyectar template-registry.service
//    Ya existe templateRegistryService, solo inyectarlo

// 4. sendTemplateTool() â†’ CUIDADO: este tiene efecto secundario
//    Necesita acceso al messageCore para enviar el template
//    SoluciÃ³n: pasar un callback/servicio por inyecciÃ³n al ToolRegistry
```

**El Ãºnico riesgo real** es `sendTemplateTool()` porque muta estado (envÃ­a un mensaje). Se resuelve inyectando el servicio como dependencia en vez de llamar por HTTP.

#### 1.3 Config inmutable per-request (fix race condition)

**Â¿PodrÃ­a romper algo?** â†’ **NO**, si se mantiene la misma interfaz de entrada/salida.

El problema actual:
```
T=0ms  Cuenta A: onConfigChange({ model: 'gpt-4o' })
T=1ms  Cuenta B: onConfigChange({ model: 'llama-3.1-8b' })  â† SOBREESCRIBE config de A
T=5ms  Cuenta A: generateSuggestion()  â† USA modelo de B (BUG)
```

La soluciÃ³n es pasar la config como parÃ¡metro, no mutarla en el singleton:

```typescript
// Cambio de firma:
// ANTES:
async generateSuggestion(event, context, recipientAccountId): Promise<AISuggestion | null>

// DESPUÃ‰S:
async generateSuggestion(params: {
  event: MessageEvent;
  context: ContextData;
  accountId: string;
  config: FluxCoreConfig;        // inmutable, per-request
  composition: AssistantComposition;  // ya resuelto
}): Promise<AISuggestion | null>
```

Internamente, el mÃ©todo usa `params.config` en vez de `this.config`. El singleton sigue existiendo pero ya no muta estado entre requests.

#### 1.4 Descomponer `ai.service.ts`

**Â¿CÃ³mo hacerlo sin degradaciÃ³n?**

Estrategia: **Extract & Delegate** â€” el singleton `AIService` sigue siendo el punto de entrada pÃºblico, pero delega a servicios internos. NingÃºn import externo cambia.

```
PASO 1: Extraer ai-branding.service.ts
  â†’ Mover: stripFluxCorePromoMarker(), appendFluxCoreBrandingFooter(),
    getSuggestionBrandingDecision(), stripFluxCoreBrandingFooterFromEnd()
  â†’ AIService mantiene wrappers que delegan
  â†’ RIESGO: Cero â€” son funciones puras sin side effects

PASO 2: Extraer ai-suggestion-store.ts
  â†’ Mover: suggestions Map, getSuggestion(), approveSuggestion(),
    rejectSuggestion(), editSuggestion(), getPendingSuggestions()
  â†’ RIESGO: Cero â€” CRUD en memoria, sin dependencias externas

PASO 3: Extraer ai-trace.service.ts
  â†’ Mover: listTraces(), getTrace(), clearTraces(), exportTraces()
  â†’ RIESGO: Cero â€” delegaciÃ³n pura a extension.listTraces/getTrace

PASO 4: Extraer ai-context.service.ts
  â†’ Mover: buildContext()
  â†’ RIESGO: Bajo â€” solo queries DB (accounts, conversations, relationships, messages)

PASO 5: Lo que queda en ai.service.ts (~300 lÃ­neas):
  â†’ generateResponse(), executeOpenAIAssistantsPath(), loadFluxCoreModule(),
    getFluxCoreExtension(), emitSuggestion(), setWebSocketEmitter()
  â†’ Este es el core real del servicio
```

**Regla de oro:** En cada paso, correr `bun run build` para verificar que compila. Si compila, no hay degradaciÃ³n.

#### 1.5 Structured logging

**Â¿PodrÃ­a romper algo?** â†’ **NO.** Es puramente aditivo.

```typescript
// Crear apps/api/src/utils/logger.ts
const LOG_LEVEL = process.env.LOG_LEVEL || 'info';
const levels = { debug: 0, info: 1, warn: 2, error: 3 };

export const logger = {
  debug: (msg: string, data?: Record<string, any>) => {
    if (levels[LOG_LEVEL] <= 0) console.log(`[DEBUG] ${msg}`, data || '');
  },
  info: (msg: string, data?: Record<string, any>) => {
    if (levels[LOG_LEVEL] <= 1) console.log(`[INFO] ${msg}`, data || '');
  },
  warn: (msg: string, data?: Record<string, any>) => {
    if (levels[LOG_LEVEL] <= 2) console.warn(`[WARN] ${msg}`, data || '');
  },
  error: (msg: string, data?: Record<string, any>) => {
    if (levels[LOG_LEVEL] <= 3) console.error(`[ERROR] ${msg}`, data || '');
  },
};
```

En producciÃ³n: `LOG_LEVEL=warn` elimina todo el ruido de debug/info. En desarrollo: `LOG_LEVEL=debug` muestra todo.

---

### Fase 2: Foundations (2-3 semanas) âœ… COMPLETADA 2026-02-09

#### 2.1 Persistir traces en DB + Sistema de SeÃ±ales IA âœ…

**Implementado:**
- Tabla `ai_traces` creada (migraciÃ³n `035_ai_persistence.sql`)
- Tabla `ai_signals` creada para seÃ±ales internas del LLM
- `ai-trace.service.ts` reescrito: persiste a DB con fallback a extensiÃ³n in-memory
- MÃ©todos `persistTrace()` y `persistSignals()` disponibles
- `ai.service.ts` invoca `persistTrace()` fire-and-forget tras cada generaciÃ³n
- Parser de `|||SIGNALS|||` implementado en `ai.service.ts` (`parseSignals`/`stripSignalBlock`)

**Riesgos de migraciÃ³n:** MÃ­nimos. Los traces estaban en un `Map<string, AITraceEntry>` en memoria. No habÃ­a datos que migrar.

**Concepto de SeÃ±ales IA (AI Signals):**

La idea de etiquetado interno por asistentes es excelente y crea una capa de **inteligencia acumulativa**. Propuesta de diseÃ±o:

##### Sintaxis recomendada

En lugar de brackets `[silenciarIA]` dentro del texto (que el usuario podrÃ­a ver), usar un **canal estructurado separado** del contenido:

```typescript
// El LLM retorna su respuesta normal + seÃ±ales en un JSON estructurado
interface AIResponse {
  content: string;           // "Lamento mucho la situaciÃ³n, vamos a resolverlo..."
  signals?: AISignal[];      // Nunca se muestran al usuario
}

interface AISignal {
  type: string;              // CategorÃ­a de la seÃ±al
  value: string;             // Valor o acciÃ³n
  confidence: number;        // 0.0 - 1.0
  metadata?: Record<string, any>;
}
```

**CategorÃ­as de seÃ±ales propuestas:**

| Tipo | Ejemplos de value | AcciÃ³n determinista |
|------|-------------------|---------------------|
| `sentiment` | `negative`, `frustrated`, `satisfied` | Acumular score de satisfacciÃ³n |
| `action` | `silence_ai`, `disable_ai`, `escalate` | Ejecutar acciÃ³n inmediata |
| `routing` | `delegate:@ana`, `delegate:@ventas` | Derivar a otro asistente/humano |
| `conversion` | `sale_completed`, `cart_abandoned`, `lead_qualified` | Registrar evento de negocio |
| `topic` | `pricing`, `technical_support`, `complaint` | Clasificar para analytics |
| `urgency` | `low`, `medium`, `high`, `critical` | Priorizar en cola |

**CÃ³mo instruir al LLM para que genere seÃ±ales:**

Se agrega un bloque en el system prompt:

```
## SeÃ±ales Internas (NUNCA mostrar al usuario)

Al final de cada respuesta, si detectas alguna de estas situaciones,
agrega un bloque JSON delimitado por |||SIGNALS|||:

|||SIGNALS|||
[{"type":"sentiment","value":"frustrated","confidence":0.85},
 {"type":"action","value":"escalate","confidence":0.9,"metadata":{"reason":"3 quejas consecutivas"}}]
|||SIGNALS|||

CategorÃ­as disponibles: sentiment, action, routing, conversion, topic, urgency
```

La extensiÃ³n FluxCore parsea el bloque `|||SIGNALS|||`, lo extrae del contenido antes de mostrarlo al usuario, y lo persiste por separado.

##### Schema de base de datos

```sql
-- Tabla principal de traces (reemplaza Map en memoria)
CREATE TABLE ai_traces (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  account_id UUID NOT NULL REFERENCES accounts(id),
  conversation_id UUID REFERENCES conversations(id),
  message_id UUID REFERENCES messages(id),
  
  -- Metadata de ejecuciÃ³n
  runtime TEXT NOT NULL,          -- 'local' | 'openai'
  model TEXT NOT NULL,
  provider TEXT NOT NULL,
  mode TEXT NOT NULL,              -- 'suggest' | 'auto'
  
  -- Timing
  started_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  completed_at TIMESTAMPTZ,
  duration_ms INTEGER,
  
  -- Tokens
  prompt_tokens INTEGER DEFAULT 0,
  completion_tokens INTEGER DEFAULT 0,
  total_tokens INTEGER DEFAULT 0,
  
  -- Request/Response (JSONB para flexibilidad)
  request_body JSONB,             -- system prompt + messages
  response_content TEXT,
  
  -- Tool usage
  tools_offered TEXT[],
  tools_called TEXT[],
  tool_details JSONB,             -- Array de { name, args, result, durationMs }
  
  -- Attempts (fallback entre providers)
  attempts JSONB,                 -- Array de { provider, model, success, error, durationMs }
  
  created_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE INDEX idx_ai_traces_account ON ai_traces(account_id);
CREATE INDEX idx_ai_traces_conversation ON ai_traces(conversation_id);
CREATE INDEX idx_ai_traces_created ON ai_traces(created_at DESC);

-- Tabla de seÃ±ales IA (queryable, indexable, para analytics)
CREATE TABLE ai_signals (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  trace_id UUID NOT NULL REFERENCES ai_traces(id) ON DELETE CASCADE,
  account_id UUID NOT NULL REFERENCES accounts(id),
  conversation_id UUID REFERENCES conversations(id),
  relationship_id UUID REFERENCES relationships(id),
  
  -- La seÃ±al
  signal_type TEXT NOT NULL,       -- 'sentiment', 'action', 'routing', 'conversion', 'topic', 'urgency'
  signal_value TEXT NOT NULL,      -- 'frustrated', 'escalate', 'delegate:@ana', 'sale_completed'
  confidence REAL DEFAULT 1.0,     -- 0.0 - 1.0
  metadata JSONB,                  -- Datos adicionales libres
  
  -- Para acumulaciÃ³n temporal
  created_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE INDEX idx_ai_signals_account ON ai_signals(account_id);
CREATE INDEX idx_ai_signals_type_value ON ai_signals(signal_type, signal_value);
CREATE INDEX idx_ai_signals_conversation ON ai_signals(conversation_id);
CREATE INDEX idx_ai_signals_created ON ai_signals(created_at DESC);

-- Vista materializada para scores acumulados por relaciÃ³n (opcional, para performance)
-- Ejemplo: "Â¿cuÃ¡ntas seÃ±ales de frustraciÃ³n tiene este contacto en los Ãºltimos 7 dÃ­as?"
CREATE VIEW ai_signal_scores AS
SELECT
  account_id,
  relationship_id,
  signal_type,
  signal_value,
  COUNT(*) as total_count,
  AVG(confidence) as avg_confidence,
  MAX(created_at) as last_seen
FROM ai_signals
WHERE created_at > now() - INTERVAL '30 days'
GROUP BY account_id, relationship_id, signal_type, signal_value;
```

**Â¿Es bueno este enfoque?** â†’ SÃ­, porque:
1. **Separa contenido de seÃ±ales** â€” el usuario nunca ve las seÃ±ales
2. **Las seÃ±ales son queryables** â€” se pueden buscar por tipo, valor, confianza, fecha
3. **Permite acumulaciÃ³n** â€” "este contacto tiene 5 seÃ±ales de frustraciÃ³n en 7 dÃ­as â†’ escalar"
4. **Alimenta determinismo** â€” las seÃ±ales pueden disparar reglas deterministas del Agent Runtime
5. **Prepara bigdata/ML** â€” los datos estÃ¡n normalizados para exportaciÃ³n a pipelines de ML
6. **JSONB metadata** â€” flexibilidad total sin migraciones constantes

**Mejoras futuras:**
- Agregar `relationship_id` para acumular seÃ±ales por contacto, no solo por conversaciÃ³n
- TimescaleDB para series temporales si el volumen crece
- ExportaciÃ³n periÃ³dica a data warehouse para ML

#### 2.2 Persistir suggestions en DB âœ…

**Implementado:**
- Tabla `ai_suggestions` creada (migraciÃ³n `035_ai_persistence.sql`)
- `ai-suggestion-store.ts` reescrito: cache en memoria + write-through a DB
- `set()` persiste fire-and-forget, `approve()`/`reject()`/`edit()` actualizan DB
- Schema Drizzle en `packages/db/src/schema/ai-suggestions.ts`

#### 2.3 Rate limiting per-account âœ…

**Â¿CÃ³mo controlarlo desde tu cuenta de super admin?**

Ya existe infraestructura en `system-admin.service.ts` y `system-admin.routes.ts` (22 matches de isAdmin). La propuesta:

```sql
-- Nueva tabla (o columna en account_ai_entitlements)
ALTER TABLE account_ai_entitlements ADD COLUMN rate_limits JSONB DEFAULT '{
  "maxRequestsPerMinute": 10,
  "maxRequestsPerHour": 100,
  "maxTokensPerDay": 50000,
  "cooldownAfterBurstMs": 5000
}';
```

**UI en panel de Super Admin:**

```
System Admin â†’ Cuentas â†’ [Cuenta X] â†’ Rate Limits
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rate Limits para @empresa-xyz            â”‚
â”‚                                          â”‚
â”‚ Requests/minuto:  [====10====]           â”‚
â”‚ Requests/hora:    [===100====]           â”‚
â”‚ Tokens/dÃ­a:       [==50000===]           â”‚
â”‚ Cooldown burst:   [===5000ms=]           â”‚
â”‚                                          â”‚
â”‚ [Aplicar defaults]  [Guardar]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Solo los usuarios con rol `system-admin` (tabla `system_admins`) pueden acceder. El middleware `isAdmin` que ya existe protege estas rutas.

#### 2.4 Circuit breaker para providers âœ…

**Implementado:** `ai-circuit-breaker.service.ts` con estados closed/open/half-open. Si un provider falla 3 veces consecutivas, circuito abierto por 60s. Tras cooldown, permite 1 probe half-open. Success â†’ cierra circuito. Admin puede resetear manualmente.

#### 2.5 Agent Flow schema + DB table

Ver Fase 3 para detalle.

---

### Fase 3: Agent Runtime Engine (3-4 semanas)

#### 3.1 Engine bÃ¡sico (sequential graph walker)

El motor que ejecuta un flujo paso a paso. Recorre el grafo de agentes en orden, pasando el contexto acumulado de un step al siguiente.

#### 3.2 Agent types: LLM, RAG, Deterministic, Tool

**Â¿RAG se considera una tool?**

**Ambas cosas.** Depende del contexto:

| Contexto | RAG es... | Porque... |
|----------|-----------|-----------|
| Dentro de un asistente single-agent | **Tool** (`search_knowledge`) | El LLM decide cuÃ¡ndo buscar, vÃ­a function calling |
| Dentro de un Agent Flow multi-agent | **Agent Type** propio | Tiene lÃ³gica autÃ³noma: recibe query, busca en vector stores, rankea resultados, retorna contexto. No necesita un LLM para ejecutarse |
| ArquitectÃ³nicamente | **Capacidad** | Es una capacidad que puede manifestarse como tool o como agent segÃºn el diseÃ±o del flujo |

En el Agent Runtime Engine, RAG es un **agent type** porque:
- Puede ejecutarse independientemente (no requiere LLM para funcionar)
- Tiene configuraciÃ³n propia (topK, minScore, vectorStoreIds)
- Produce output estructurado que otros agents consumen
- En un flujo, un RAG agent puede correr **en paralelo** con otros agents

Pero **tambiÃ©n sigue siendo tool** dentro de asistentes single-agent (como funciona hoy con `search_knowledge`). Ambos patrones coexisten.

#### 3.3 Context bus (shared state entre agents)

Mecanismo append-only e inmutable para que cada agent escriba sus outputs y el siguiente pueda leerlos.

#### 3.4 Condition evaluator

EvalÃºa expresiones como `{{ intent-classifier.intent == 'queja' }}` para decidir branches condicionales.

#### 3.5 Scope enforcer

Valida que cada agent no exceda sus lÃ­mites (tokens, tiempo, tools permitidas).

---

### Fase 4: Multi-Agent Features (3-4 semanas)

**Â¿Se puede lograr usando las mismas interfaces que tenemos?**

**SÃ.** Tu modelo mental es correcto y es la mejor forma de pensarlo:

> "Un agente es una carpeta que contiene asistentes, herramientas, base de conocimiento, instrucciones. Lo que determina el comportamiento es el flujo."

Esto se mapea perfectamente a la arquitectura existente:

```
ENTIDADES EXISTENTES (ya en DB):
â”œâ”€â”€ fluxcore_assistants     â†’ Un asistente con modelConfig, timingConfig
â”œâ”€â”€ fluxcore_instructions   â†’ System prompts con versiones
â”œâ”€â”€ fluxcore_vector_stores  â†’ Bases de conocimiento
â”œâ”€â”€ fluxcore_tools          â†’ Tools registradas
â””â”€â”€ fluxcore_tool_connections â†’ Conexiones toolâ†”assistant

NUEVA ENTIDAD:
â””â”€â”€ fluxcore_agents         â†’ Un AGENTE es una composiciÃ³n de las entidades existentes
                              + un FLUJO que define cÃ³mo interactÃºan
```

**Modelo de datos del Agent:**

```sql
CREATE TABLE fluxcore_agents (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  account_id UUID NOT NULL REFERENCES accounts(id),
  name TEXT NOT NULL,
  description TEXT,
  status TEXT NOT NULL DEFAULT 'draft',  -- 'draft' | 'active' | 'archived'
  
  -- El flujo que define el comportamiento
  flow JSONB NOT NULL DEFAULT '{"steps":[]}',
  
  -- Scopes de seguridad
  scopes JSONB NOT NULL DEFAULT '{
    "allowedModels": [],
    "maxTotalTokens": 5000,
    "maxExecutionTimeMs": 30000,
    "allowedTools": [],
    "canCreateSubAgents": false
  }',
  
  -- Trigger: cuÃ¡ndo se activa este agente
  trigger_config JSONB DEFAULT '{"type":"message_received"}',
  
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

-- RelaciÃ³n N:M â€” Un agente "contiene" asistentes existentes
CREATE TABLE fluxcore_agent_assistants (
  agent_id UUID NOT NULL REFERENCES fluxcore_agents(id) ON DELETE CASCADE,
  assistant_id UUID NOT NULL REFERENCES fluxcore_assistants(id),
  role TEXT NOT NULL DEFAULT 'worker',  -- 'router', 'worker', 'reviewer'
  step_id TEXT,  -- ID del step en el flow JSON donde se usa este asistente
  PRIMARY KEY (agent_id, assistant_id)
);
```

**UI propuesta â€” Solapa "Agentes" en FluxCore Sidebar:**

```
FluxCore Sidebar (existente):
â”œâ”€â”€ Uso
â”œâ”€â”€ Asistentes         â† sigue existiendo, CRUD individual de asistentes
â”œâ”€â”€ Instrucciones      â† sigue existiendo
â”œâ”€â”€ Base de conocimiento â† sigue existiendo
â”œâ”€â”€ Herramientas       â† sigue existiendo
â”œâ”€â”€ ğŸ†• Agentes         â† NUEVA solapa
â”œâ”€â”€ Debug
â””â”€â”€ FacturaciÃ³n
```

**Vista de Agentes:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤– Agentes                              [+ Crear]   â”‚
â”‚                                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ ğŸŸ¢ Soporte al Cliente                         â”‚   â”‚
â”‚ â”‚ 3 asistentes Â· 2 tools Â· 1 base de conocimientoâ”‚   â”‚
â”‚ â”‚ Trigger: Mensaje recibido                      â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ âšª Calificador de Leads (draft)                â”‚   â”‚
â”‚ â”‚ 2 asistentes Â· 1 tool                          â”‚   â”‚
â”‚ â”‚ Trigger: Primer mensaje                        â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Editor de Agente (al hacer click):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† Agentes / Soporte al Cliente                      â”‚
â”‚                                                      â”‚
â”‚ â”Œâ”€ Componentes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚                                                â”‚   â”‚
â”‚ â”‚ ğŸ§© Asistentes:                                 â”‚   â”‚
â”‚ â”‚   [Clasificador] [Responder Producto] [Quejas] â”‚   â”‚
â”‚ â”‚   + Agregar asistente existente                 â”‚   â”‚
â”‚ â”‚                                                â”‚   â”‚
â”‚ â”‚ ğŸ”§ Herramientas: [search_knowledge] [templates]â”‚   â”‚
â”‚ â”‚ ğŸ“š Conocimiento: [CatÃ¡logo Productos]          â”‚   â”‚
â”‚ â”‚ ğŸ“ Instrucciones: [PolÃ­tica Soporte v2]        â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                      â”‚
â”‚ â”Œâ”€ Flujo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚                                                â”‚   â”‚
â”‚ â”‚  [Mensaje] â†’ [Clasificador] â†’â”¬â†’ [Producto]    â”‚   â”‚
â”‚ â”‚                               â”œâ†’ [Quejas]      â”‚   â”‚
â”‚ â”‚                               â””â†’ [Responder]   â”‚   â”‚
â”‚ â”‚                                                â”‚   â”‚
â”‚ â”‚  [Editar flujo JSON]  [Editor visual]          â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                      â”‚
â”‚ â”Œâ”€ Scopes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ Tokens mÃ¡x: [5000]  Tiempo mÃ¡x: [30s]          â”‚   â”‚
â”‚ â”‚ Tools permitidas: [search_knowledge, templates] â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Lo que las fichas representan:**
- Cada asistente en la solapa "Asistentes" es una **ficha reutilizable**
- Un agente **compone** esas fichas en un flujo
- Si se modifica un asistente en "Asistentes", el cambio se refleja en todos los agentes que lo usan
- El agente NO duplica asistentes, los referencia

**Esto NO requiere reescribir nada existente.** Los asistentes, instrucciones, tools y vector stores siguen funcionando exactamente igual. El agente es una capa nueva que los orquesta.

#### 4.1 Router agent
El primer step de un flujo que clasifica la intenciÃ³n y decide quÃ© branch seguir. Es un asistente con `temperature: 0.1` y un output schema JSON estricto.

#### 4.2 Parallel execution
Agents independientes que corren simultÃ¡neamente. Ejemplo: buscar en knowledge base Y clasificar sentimiento al mismo tiempo.

#### 4.3 Human-in-the-loop
Un step que pausa el flujo y envÃ­a una notificaciÃ³n al humano. El humano aprueba/rechaza/edita y el flujo continÃºa. Ya existe parcialmente con el modo `suggest` de los asistentes.

#### 4.4 Agent Flow editor (UI visual)
Un editor drag-and-drop para construir flujos visualmente. Puede empezar como editor JSON con preview del grafo, y evolucionar a visual.

#### 4.5 JSON-to-Flow API
Endpoint REST para crear/actualizar flujos desde JSON. Permite automatizaciÃ³n y integraciÃ³n con herramientas externas.

---

### Fase 5: Enterprise (ongoing)
- [ ] OpenTelemetry integration
- [ ] Per-tenant API key management
- [ ] A/B testing de flujos
- [ ] Agent quality metrics (usando AI Signals para medir satisfacciÃ³n, conversiones, etc.)
- [ ] Self-improvement loops (usar seÃ±ales acumuladas para auto-ajustar prompts)

---

## 10. RESUMEN EJECUTIVO

| Pregunta | Respuesta |
|----------|-----------|
| Â¿Funciona? | SÃ­, para single-agent simple |
| Â¿Es enterprise? | En progreso. Race conditions resueltas. Observability bÃ¡sica (traces DB). Rate limiting y circuit breaker implementados. Falta scaling horizontal. |
| Â¿Puede hacer los mejores agentes? | No. Es single-agent monolÃ­tico |
| Â¿Se puede simplificar? | **Ya simplificado (Fase 1).** ~380 lÃ­neas eliminadas, 4 HTTP self-calls reemplazados, God Object descompuesto |
| Â¿Se puede crear flujos desde JSON? | No hoy. Requiere Agent Runtime Engine (Fase 3) |
| Â¿QuÃ© falta mÃ¡s urgente? | Fase 3: Agent Runtime Engine (multi-agente, router, parallel execution) |
| Â¿Rompe algo la Fase 1? | **Completada sin regresiones.** Build API verificado OK |
| Â¿RAG es una tool? | Ambos: tool dentro de single-agent, agent type dentro de multi-agent |
| Â¿Se reusan las interfaces existentes? | SÃ­. Un agente es una composiciÃ³n de asistentes/tools/KB existentes + un flujo |
| Â¿Sistema de seÃ±ales IA? | Excelente idea. Tabla `ai_signals` con tipo/valor/confianza, queryable para analytics y ML |

**El cÃ³digo actual tiene buenos cimientos** (EventBus, ExecutionPlan, ToolRegistry, RAG-as-Tool). **Fase 1 (Limpieza) y Fase 2 (Foundations) completadas.** Traces, signals y suggestions persistidos en DB. Rate limiting y circuit breaker activos. La base estÃ¡ lista para Fase 3 (Agent Runtime Engine).

**La visiÃ³n de "agente como carpeta de fichas + flujo" es la correcta** â€” se mapea 1:1 con la arquitectura existente sin reescrituras, y las entidades actuales (asistentes, instrucciones, vector stores, tools) se convierten en piezas componibles de un sistema mÃ¡s poderoso.
