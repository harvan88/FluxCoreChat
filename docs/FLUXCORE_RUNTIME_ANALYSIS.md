# FluxCore Runtime â€” AnÃ¡lisis ArquitectÃ³nico Completo

**Fecha:** 2026-02-09  
**Alcance:** Todo el runtime de IA: orquestaciÃ³n, extensiÃ³n, ejecuciÃ³n, RAG, tools, crÃ©ditos  
**Veredicto general:** Funcional pero con deuda tÃ©cnica significativa. No es enterprise-ready. No soporta multi-agente.

---

## 1. ARQUITECTURA ACTUAL â€” FLUJO COMPLETO DE UN MENSAJE

```
Usuario envÃ­a mensaje
       â”‚
       â–¼
  MessageCore.receive()          â† core/message-core.ts
       â”‚
       â”œâ”€ 1. Persistir mensaje (DB)
       â”œâ”€ 2. WebSocket broadcast
       â”œâ”€ 3. AutomationController.evaluateTrigger()
       â”œâ”€ 4. ExtensionHost.processMessage()  â† NO genera IA aquÃ­
       â””â”€ 5. CoreEventBus.emit('core:message_received')
                    â”‚
                    â–¼
           AIOrchestrator         â† ai-orchestrator.service.ts
                    â”‚
                    â”œâ”€ Validaciones (success, automatic mode, text)
                    â”œâ”€ Debounce por conversaciÃ³n (setTimeout)
                    â””â”€ extensionHost.generateAIResponse()
                              â”‚
                              â–¼
                    AIService.generateResponse()   â† ai.service.ts
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â–¼         â”‚
          resolveExecutionPlan()     â† ai-execution-plan.service.ts
                    â”‚
                    â”œâ”€ resolveActiveAssistant()
                    â”œâ”€ Check extension_installations
                    â”œâ”€ Extract modelConfig/timingConfig
                    â”œâ”€ Check entitlements
                    â”œâ”€ Check API keys
                    â”œâ”€ Credits gating (OpenAI)
                    â””â”€ Build providerOrder
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â–¼         â”‚
             runtime === 'openai'?
                /           \
               SI            NO
               â”‚              â”‚
     executeOpenAIAssistantsPath()    extension.generateSuggestion()
               â”‚                              â”‚
               â–¼                              â–¼
     runAssistantWithMessages()      FluxCoreExtension (local)
     (openai-sync.service.ts)        (extensions/fluxcore/src/index.ts)
               â”‚                              â”‚
               â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
               â”‚                    â–¼         â”‚
               â”‚          fetchActiveAssistant() â† HTTP a localhost:3000
               â”‚          buildPrompt()
               â”‚          getToolsForAssistant()
               â”‚          createChatCompletionWithFallback()
               â”‚                    â”‚
               â”‚                    â”œâ”€ Tool loop (max 2 rounds)
               â”‚                    â”‚   â”œâ”€ search_knowledge
               â”‚                    â”‚   â”œâ”€ list_available_templates
               â”‚                    â”‚   â””â”€ send_template
               â”‚                    â”‚
               â”‚                    â””â”€ Build AISuggestion
               â”‚                              â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                              â–¼
                                   AIOrchestrator
                                   messageCore.send() â† respuesta final
```

---

## 2. LO QUE ESTÃ BIEN (Aciertos)

### 2.1 ExecutionPlan como Single Source of Truth
El patrÃ³n `resolveExecutionPlan()` es sÃ³lido. Resuelve assistant, provider, crÃ©ditos y elegibilidad en **un solo paso** antes de tocar la extensiÃ³n. Discriminated union (`EligiblePlan | BlockedPlan`) es tipado correcto.

### 2.2 CoreEventBus + AIOrchestrator desacoplados
El core de mensajerÃ­a NO conoce la IA. Emite un evento (`core:message_received`) y el orchestrator escucha. Esto respeta TOTEM (IA es extensiÃ³n, no nÃºcleo).

### 2.3 RAG-as-Tool
El modelo decide si buscar en la base de conocimiento vÃ­a function calling (`search_knowledge`). Elimina bÃºsquedas innecesarias para mensajes como "ok", "gracias". Buena decisiÃ³n arquitectÃ³nica.

### 2.4 ToolRegistry extensible
El `ToolRegistry` en la extensiÃ³n es un patrÃ³n limpio: recibe dependencias por inyecciÃ³n, decide quÃ© tools ofrecer segÃºn el contexto del asistente.

### 2.5 Provider fallback con retry
`createChatCompletionWithFallback()` implementa retry con exponential backoff, mapeo de modelos entre providers, y fallback automÃ¡tico de tools si causan `bad_request`.

### 2.6 Trace/Debug completo
Cada ejecuciÃ³n genera un `AITraceEntry` con attempts, tool usage, request bodies, timing. Ãštil para debugging en producciÃ³n.

---

## 3. FALLAS CRÃTICAS

### 3.1 ğŸ”´ CÃ³digo muerto: `processMessage()` duplica `generateResponse()`
`ai.service.ts` tiene **dos mÃ©todos** que hacen casi lo mismo:
- `processMessage()` (lÃ­neas 235-546) â€” LÃ³gica legacy, resuelve assistant manualmente, usa `applyCreditsGating()` (degradaciÃ³n silenciosa)
- `generateResponse()` (lÃ­neas 1279-1372) â€” Usa `ExecutionPlan`, es el flujo correcto

**`processMessage()` es dead code** que nadie llama actualmente (el orchestrator usa `generateResponse`), pero sigue ahÃ­ con ~300 lÃ­neas, confundiendo a cualquier desarrollador nuevo.

### 3.2 ğŸ”´ La extensiÃ³n se llama a sÃ­ misma via HTTP
```typescript
// extensions/fluxcore/src/index.ts:219
const url = `http://localhost:${port}/fluxcore/runtime/active-assistant?accountId=${accountId}`;
const response = await fetch(url);
```

La extensiÃ³n FluxCore hace **HTTP calls a localhost** para obtener el assistant composition, RAG context, templates, etc. Esto es:
- **Ineficiente**: SerializaciÃ³n JSON â†’ HTTP â†’ Parsing â†’ Routing â†’ DB â†’ SerializaciÃ³n â†’ Response
- **FrÃ¡gil**: Depende de que el puerto sea correcto, de que el server estÃ© levantado
- **Circular**: El API server carga la extensiÃ³n, la extensiÃ³n le hace requests al API server

DeberÃ­a recibir esta data por inyecciÃ³n de dependencias o parÃ¡metro.

### 3.3 ğŸ”´ Doble resoluciÃ³n del assistant
Cuando el orchestrator llama a `generateResponse()`:
1. `resolveExecutionPlan()` llama a `resolveActiveAssistant()` â†’ DB query completa
2. Luego `extension.generateSuggestion()` hace **otra** llamada `fetchActiveAssistant()` via HTTP â†’ que internamente hace la misma query

El assistant se resuelve **2 veces** por mensaje. Antes era 3x (se arreglÃ³ parcialmente).

### 3.4 ğŸ”´ `ai.service.ts` es un God Object (1596 lÃ­neas)
Este archivo concentra:
- Carga de la extensiÃ³n FluxCore
- GestiÃ³n de suggestions (CRUD en memoria)
- Branding/promo markers
- Provider resolution
- API key management
- Context building
- Trace management
- WebSocket emission
- Credits gating (legacy)
- Welcome conversations
- OpenAI Assistants path
- Local runtime path

DeberÃ­a ser 5-6 servicios separados.

### 3.5 ğŸ”´ Config mutation en lugar de inmutabilidad
```typescript
// extensions/fluxcore/src/index.ts:377
Object.assign(this.config, newConfig);
```
`onConfigChange()` muta el singleton de la extensiÃ³n. Si dos cuentas distintas procesan mensajes concurrentemente, la segunda llamada a `onConfigChange()` sobreescribe la config de la primera **antes** de que termine `generateSuggestion()`. Esto es un **race condition** en producciÃ³n con mÃºltiples cuentas.

### 3.6 ğŸ”´ Logging excesivo en producciÃ³n
Hay ~80+ `console.log()` en `ai.service.ts` y ~40+ en `extensions/fluxcore/src/index.ts`. En producciÃ³n esto genera ruido masivo. No hay niveles de log (debug vs info vs warn).

### 3.7 ğŸŸ¡ Tipos `any` por doquier
```typescript
type ContextData = any;  // ai.service.ts:50
```
El tipo de contexto es `any` en el servicio principal. Los cast `as any` se usan extensivamente para bypasear TypeScript.

---

## 4. PUNTOS CRÃTICOS (Riesgos)

### 4.1 Single-threaded bottleneck
Todo corre en un solo proceso Bun. Si una llamada a OpenAI tarda 15 segundos, bloquea el event loop para todos los demÃ¡s usuarios. No hay worker threads ni queue system.

### 4.2 Suggestions en memoria (no persisten)
```typescript
const suggestions: Map<string, AISuggestion> = new Map();
```
Si el server se reinicia, se pierden todas las suggestions pendientes y traces.

### 4.3 Sin rate limiting por cuenta
No hay protecciÃ³n contra un usuario que envÃ­e 100 mensajes en 1 segundo. El debounce del orchestrator solo agrupa mensajes de la misma conversaciÃ³n, pero no limita el throughput global.

### 4.4 Sin circuit breaker
Si OpenAI estÃ¡ caÃ­do, el sistema va a reintentar indefinidamente (hasta el timeout de 15s) por cada mensaje. No hay circuit breaker que detenga los intentos despuÃ©s de N fallos consecutivos.

---

## 5. Â¿ES ENTERPRISE-READY?

**No.** Faltan estos pilares enterprise:

| Pilar | Estado actual | Necesario |
|-------|--------------|-----------|
| **Multi-tenancy isolation** | Config mutada en singleton compartido | Config per-request, inmutable |
| **Horizontal scaling** | Single process, state en memoria | Stateless workers + Redis/queue |
| **Observability** | console.log | Structured logging, OpenTelemetry, metrics |
| **Fault tolerance** | Sin circuit breaker, sin retry queue | Circuit breakers, dead letter queues |
| **Security** | API keys en env vars compartidas | Per-tenant key vault, key rotation |
| **Rate limiting** | Ninguno | Per-account, per-provider throttling |
| **Audit trail** | Traces en memoria | Traces persistidos, compliance-ready |
| **A/B testing** | Ninguno | Feature flags, canary deployments |
| **Multi-agent** | âŒ No existe | Orchestration layer, agent graphs |

---

## 6. Â¿ESTÃ PREPARADO PARA HACER LOS MEJORES AGENTES?

**No.** El sistema actual es un **single-agent monolÃ­tico**. Un asistente recibe un mensaje, genera una respuesta. No hay:

- **No hay composiciÃ³n de agentes**: No se puede crear un pipeline donde Agent A analiza la intenciÃ³n, Agent B busca informaciÃ³n, Agent C formula la respuesta
- **No hay routing inteligente**: No hay un "router agent" que decida quÃ© sub-agente usar
- **No hay estado de conversaciÃ³n multi-step**: No hay memoria de working state entre turnos (solo el historial de mensajes crudos)
- **No hay ejecuciÃ³n determinista**: Todo depende del LLM. No hay steps deterministas intercalados
- **No hay grafos de ejecuciÃ³n**: No se puede definir "si el usuario pide X, ejecutar workflow Y con steps [Aâ†’Bâ†’C]"
- **No hay evaluaciÃ³n de calidad**: No hay self-critique, no hay verificaciÃ³n de output

---

## 7. PROPUESTA: ARQUITECTURA MICRO-AGENTES

### 7.1 Concepto: Agent Graph + Deterministic Steps

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Agent Orchestrator    â”‚
                    â”‚  (Deterministic Router)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼              â–¼              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Intent    â”‚  â”‚ Knowledgeâ”‚  â”‚ Action   â”‚
        â”‚ Classifierâ”‚  â”‚ Agent    â”‚  â”‚ Executor â”‚
        â”‚ (LLM)     â”‚  â”‚ (RAG)    â”‚  â”‚ (Tools)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚              â”‚              â”‚
              â–¼              â–¼              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Response  â”‚  â”‚ Quality  â”‚  â”‚ Guard    â”‚
        â”‚ Generator â”‚  â”‚ Checker  â”‚  â”‚ Rails    â”‚
        â”‚ (LLM)     â”‚  â”‚ (Det.)   â”‚  â”‚ (Det.)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 DefiniciÃ³n de un Agent Flow (JSON)

Un asistente autorizado podrÃ­a crear un flujo desde un JSON como este:

```json
{
  "id": "customer-support-flow",
  "name": "Soporte al Cliente",
  "version": "1.0",
  "trigger": { "type": "message_received" },
  "agents": [
    {
      "id": "intent-classifier",
      "type": "llm",
      "model": "llama-3.1-8b-instant",
      "systemPrompt": "Clasifica la intenciÃ³n del usuario en: pregunta_producto, queja, saludo, otro",
      "outputSchema": {
        "type": "object",
        "properties": {
          "intent": { "enum": ["pregunta_producto", "queja", "saludo", "otro"] },
          "confidence": { "type": "number" },
          "entities": { "type": "object" }
        }
      },
      "maxTokens": 100,
      "temperature": 0.1
    },
    {
      "id": "knowledge-lookup",
      "type": "rag",
      "condition": "{{ intent-classifier.intent == 'pregunta_producto' }}",
      "vectorStoreIds": ["vs_productos"],
      "topK": 5,
      "minScore": 0.3
    },
    {
      "id": "response-generator",
      "type": "llm",
      "model": "gpt-4o-mini",
      "systemPrompt": "Genera una respuesta usando el contexto proporcionado...",
      "inputs": {
        "user_message": "{{ trigger.content }}",
        "intent": "{{ intent-classifier.intent }}",
        "knowledge": "{{ knowledge-lookup.context }}",
        "customer_history": "{{ context.relationship }}"
      },
      "maxTokens": 500,
      "temperature": 0.7
    },
    {
      "id": "quality-gate",
      "type": "deterministic",
      "checks": [
        { "rule": "response.length > 10", "action": "pass" },
        { "rule": "response.contains_pii", "action": "redact" },
        { "rule": "confidence < 0.5", "action": "escalate_to_human" }
      ]
    },
    {
      "id": "send-template",
      "type": "tool",
      "condition": "{{ intent-classifier.intent == 'queja' && quality-gate.action == 'pass' }}",
      "tool": "send_template",
      "params": {
        "templateId": "complaint-acknowledgment",
        "variables": { "name": "{{ context.relationship.contactName }}" }
      }
    }
  ],
  "scopes": {
    "allowedModels": ["llama-3.1-8b-instant", "gpt-4o-mini"],
    "maxTotalTokens": 2000,
    "maxExecutionTimeMs": 30000,
    "allowedTools": ["search_knowledge", "send_template"],
    "canCreateSubAgents": false
  }
}
```

### 7.3 QuÃ© se necesita construir

#### Capa 1: Agent Runtime Engine
```
apps/api/src/services/agent-runtime/
â”œâ”€â”€ engine.ts              â€” Ejecuta un AgentFlow (graph walker)
â”œâ”€â”€ agent-types.ts         â€” LLMAgent, RAGAgent, DeterministicAgent, ToolAgent
â”œâ”€â”€ context-bus.ts         â€” Shared context entre agents (inmutable, append-only)
â”œâ”€â”€ condition-evaluator.ts â€” EvalÃºa expresiones tipo {{ intent == 'x' }}
â”œâ”€â”€ scope-enforcer.ts      â€” Valida lÃ­mites (tokens, tiempo, tools)
â””â”€â”€ flow-registry.ts       â€” CRUD de AgentFlows (DB-backed)
```

#### Capa 2: Agent Types

| Tipo | Comportamiento | Determinista? |
|------|---------------|---------------|
| `llm` | Llama a un LLM con system prompt + inputs | No |
| `rag` | Busca en vector stores | Semi (query es del paso anterior) |
| `deterministic` | Reglas if/then/else | SÃ­ |
| `tool` | Ejecuta una tool registrada | SÃ­ |
| `router` | Decide quÃ© branch del grafo seguir | Configurable |
| `human-in-loop` | Pausa y espera aprobaciÃ³n humana | SÃ­ |
| `transform` | Transforma data (map, filter, extract) | SÃ­ |

#### Capa 3: Scoped Execution
Cada flow se ejecuta dentro de un **scope** que define:
- QuÃ© modelos puede usar
- CuÃ¡ntos tokens puede consumir
- QuÃ© tools puede invocar
- Tiempo mÃ¡ximo de ejecuciÃ³n
- Si puede crear sub-flujos

Esto permite que un asistente autorizado cree flujos sin riesgo de escalada de privilegios.

---

## 8. SIMPLIFICACIÃ“N INMEDIATA DEL CÃ“DIGO ACTUAL

### 8.1 Eliminar dead code
- **Borrar `processMessage()`** de `ai.service.ts` (~300 lÃ­neas)
- **Borrar `applyCreditsGating()`** â€” ya lo hace `resolveExecutionPlan`
- **Borrar `getAccountConfig()` completo** â€” duplica lÃ³gica del ExecutionPlan

### 8.2 Eliminar HTTP self-calls en la extensiÃ³n
En lugar de que la extensiÃ³n haga `fetch(localhost:3000/...)`, pasar la data como parÃ¡metro:

```typescript
// ANTES (malo):
const active = await this.fetchActiveAssistant(recipientAccountId); // HTTP call

// DESPUÃ‰S (bueno):
async generateSuggestion(event, context, recipientAccountId, composition) {
  // composition ya viene resuelta del ExecutionPlan
}
```

Esto elimina ~4 HTTP round-trips por mensaje.

### 8.3 Config inmutable per-request
```typescript
// ANTES (race condition):
await extension.onConfigChange(recipientAccountId, { ... });
const suggestion = await extension.generateSuggestion(event, context, recipientAccountId);

// DESPUÃ‰S (seguro):
const suggestion = await extension.generateSuggestion(event, context, {
  accountId: recipientAccountId,
  config: { model, temperature, providerOrder, ... },  // inmutable per-request
  composition,  // ya resuelto
});
```

### 8.4 Descomponer ai.service.ts
```
ai.service.ts (1596 lÃ­neas) â†’
â”œâ”€â”€ ai-generation.service.ts    â€” generateResponse() + OpenAI path
â”œâ”€â”€ ai-context.service.ts       â€” buildContext()
â”œâ”€â”€ ai-branding.service.ts      â€” promo markers, branding footer
â”œâ”€â”€ ai-suggestion-store.ts      â€” CRUD suggestions (migrar a Redis)
â””â”€â”€ ai-trace.service.ts         â€” listTraces, getTrace, exportTraces
```

### 8.5 Structured logging
Reemplazar `console.log('[ai-service] ...')` con:
```typescript
import { logger } from '../utils/logger';
logger.info('generateResponse', { accountId, runtime, provider, elapsedMs });
logger.debug('providerOrder', { providers: providerOrder.map(p => p.provider) });
```

---

## 9. ROADMAP PROPUESTO

### Fase 1: Limpieza (1-2 semanas)
- [ ] Eliminar `processMessage()` dead code
- [ ] Eliminar HTTP self-calls en extensiÃ³n
- [ ] Config inmutable per-request (fix race condition)
- [ ] Descomponer `ai.service.ts`
- [ ] Structured logging

### Fase 2: Foundations (2-3 semanas)
- [ ] Persistir traces en DB (no en memoria)
- [ ] Persistir suggestions en DB/Redis
- [ ] Rate limiting per-account
- [ ] Circuit breaker para providers
- [ ] Agent Flow schema + DB table

### Fase 3: Agent Runtime Engine (3-4 semanas)
- [ ] Engine bÃ¡sico (sequential graph walker)
- [ ] Agent types: LLM, RAG, Deterministic, Tool
- [ ] Context bus (shared state entre agents)
- [ ] Condition evaluator
- [ ] Scope enforcer

### Fase 4: Multi-Agent Features (3-4 semanas)
- [ ] Router agent (intent classification â†’ branch)
- [ ] Parallel execution (agents independientes en paralelo)
- [ ] Human-in-the-loop (pausa, notificaciÃ³n, aprobaciÃ³n)
- [ ] Agent Flow editor (UI visual)
- [ ] JSON-to-Flow API (crear flujos desde configuraciÃ³n)

### Fase 5: Enterprise (ongoing)
- [ ] OpenTelemetry integration
- [ ] Per-tenant API key management
- [ ] A/B testing de flujos
- [ ] Agent quality metrics
- [ ] Self-improvement loops

---

## 10. RESUMEN EJECUTIVO

| Pregunta | Respuesta |
|----------|-----------|
| Â¿Funciona? | SÃ­, para single-agent simple |
| Â¿Es enterprise? | No. Race conditions, sin scaling, sin observability |
| Â¿Puede hacer los mejores agentes? | No. Es single-agent monolÃ­tico |
| Â¿Se puede simplificar? | SÃ­. ~500 lÃ­neas de dead code, HTTP self-calls innecesarios |
| Â¿Se puede crear flujos desde JSON? | No hoy. Requiere Agent Runtime Engine (Fase 3) |
| Â¿QuÃ© falta mÃ¡s urgente? | Fix race condition de config + eliminar dead code + eliminar HTTP self-calls |

**El cÃ³digo actual tiene buenos cimientos** (EventBus, ExecutionPlan, ToolRegistry, RAG-as-Tool) pero necesita una limpieza profunda antes de construir la capa de multi-agente encima.
